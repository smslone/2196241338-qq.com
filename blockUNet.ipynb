{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torchvision import  transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weights_init(m):\n",
    "    # 初始化权重函数\n",
    "    classname = m.__class__.__name__\n",
    "    # 获取当前层的类名\n",
    "    if classname.find('Conv') != -1:\n",
    "        # 如果当前层是卷积层\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        # 将权重初始化为均值为0，标准差为0.02的正态分布\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        # 如果当前层是批归一化层\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        # 将权重初始化为均值为1，标准差为0.02的正态分布\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "        # 将偏置初始化为0\n",
    "def blockUNet(in_c, out_c, name, transposed=False, bn=True, relu=True, size=4, pad=1, dropout=0.):\n",
    "    # 定义UNet块函数\n",
    "    block = nn.Sequential()\n",
    "    # 创建一个Sequential容器，用于存储UNet块中的各个层\n",
    "    if relu:\n",
    "        # 如果需要ReLU激活函数\n",
    "        block.add_module('%s_relu' % name, nn.ReLU(inplace=True))\n",
    "        # 添加ReLU激活函数\n",
    "    else:\n",
    "        # 如果需要LeakyReLU激活函数\n",
    "        block.add_module('%s_leakyrelu' % name, nn.LeakyReLU(0.2, inplace=True))\n",
    "        # 添加LeakyReLU激活函数\n",
    "    if not transposed:\n",
    "        # 如果不是转置卷积\n",
    "        block.add_module('%s_conv' % name, nn.Conv2d(in_c, out_c, kernel_size=size, stride=2, padding=pad, bias=True))\n",
    "        # 添加卷积层\n",
    "    else:\n",
    "        # 如果是转置卷积\n",
    "        block.add_module('%s_upsam' % name, nn.Upsample(scale_factor=2, mode='bilinear')) # Note: old default was nearest neighbor\n",
    "        # 添加上采样层\n",
    "        # reduce kernel size by one for the upsampling (ie decoder part)\n",
    "        block.add_module('%s_tconv' % name, nn.Conv2d(in_c, out_c, kernel_size=(size-1), stride=1, padding=pad, bias=True))\n",
    "        # 添加转置卷积层\n",
    "    if bn:\n",
    "        # 如果需要批归一化\n",
    "        block.add_module('%s_bn' % name, nn.BatchNorm2d(out_c))\n",
    "        # 添加批归一化层\n",
    "    if dropout>0.:\n",
    "        # 如果需要dropout\n",
    "        block.add_module('%s_dropout' % name, nn.Dropout2d( dropout, inplace=True))\n",
    "        # 添加dropout层\n",
    "    return block\n",
    "    \n",
    "# generator model\n",
    "class TurbNetG(nn.Module):\n",
    "    def __init__(self, channelExponent=6, dropout=0.):\n",
    "        super(TurbNetG, self).__init__()\n",
    "        # 计算通道数\n",
    "        channels = int(2 ** channelExponent + 0.5)\n",
    "\n",
    "        # 第一层\n",
    "        self.layer1 = nn.Sequential()\n",
    "        self.layer1.add_module('layer1_conv', nn.Conv2d(1, channels, 4, 2, 1, bias=True))\n",
    "\n",
    "        # 第二层\n",
    "        self.layer2 = blockUNet(channels  , channels*2, 'layer2', transposed=False, bn=True,  relu=False, dropout=dropout )\n",
    "        # 第二层b\n",
    "        self.layer2b= blockUNet(channels*2, channels*2, 'layer2b',transposed=False, bn=True,  relu=False, dropout=dropout )\n",
    "        # 第三层\n",
    "        self.layer3 = blockUNet(channels*2, channels*4, 'layer3', transposed=False, bn=True,  relu=False, dropout=dropout )\n",
    "        # note the following layer also had a kernel size of 2 in the original version (cf https://arxiv.org/abs/1810.08217)\n",
    "        # it is now changed to size 4 for encoder/decoder symmetry; to reproduce the old/original results, please change it to 2\n",
    "        self.layer4 = blockUNet(channels*4, channels*8, 'layer4', transposed=False, bn=True,  relu=False, dropout=dropout ,  size=4 ) # note, size 4!\n",
    "        self.layer5 = blockUNet(channels*8, channels*8, 'layer5', transposed=False, bn=True,  relu=False, dropout=dropout , size=2,pad=0)\n",
    "        self.layer6 = blockUNet(channels*8, channels*8, 'layer6', transposed=False, bn=False, relu=False, dropout=dropout , size=2,pad=0)\n",
    "     \n",
    "        # note, kernel size is internally reduced by one now\n",
    "        self.dlayer6 = blockUNet(channels*8, channels*8, 'dlayer6', transposed=True, bn=True, relu=True, dropout=dropout , size=2,pad=0)\n",
    "        self.dlayer5 = blockUNet(channels*16,channels*8, 'dlayer5', transposed=True, bn=True, relu=True, dropout=dropout , size=2,pad=0)\n",
    "        self.dlayer4 = blockUNet(channels*16,channels*4, 'dlayer4', transposed=True, bn=True, relu=True, dropout=dropout ) \n",
    "        self.dlayer3 = blockUNet(channels*8, channels*2, 'dlayer3', transposed=True, bn=True, relu=True, dropout=dropout )\n",
    "        self.dlayer2b= blockUNet(channels*4, channels*2, 'dlayer2b',transposed=True, bn=True, relu=True, dropout=dropout )\n",
    "        self.dlayer2 = blockUNet(channels*4, channels  , 'dlayer2', transposed=True, bn=True, relu=True, dropout=dropout )\n",
    "\n",
    "        self.dlayer1 = nn.Sequential()\n",
    "        self.dlayer1.add_module('dlayer1_relu', nn.ReLU(inplace=True))\n",
    "        self.dlayer1.add_module('dlayer1_tconv', nn.ConvTranspose2d(channels*2, 1, 4, 2, 1, bias=True))\n",
    "        #self.dlayer1.add_module('dlayer1_tconv', nn.ConvTranspose2d(1, 3, 4, 2, 1, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 将输入x经过layer1得到out1\n",
    "        out1 = self.layer1(x)\n",
    "        # 将out1经过layer2得到out2\n",
    "        out2 = self.layer2(out1)\n",
    "        # 将out2经过layer2b得到out2b\n",
    "        out2b= self.layer2b(out2)\n",
    "        # 将out2b经过layer3得到out3\n",
    "        out3 = self.layer3(out2b)\n",
    "        # 将out3经过layer4得到out4\n",
    "        out4 = self.layer4(out3)\n",
    "        # 将out4经过layer5得到out5\n",
    "        out5 = self.layer5(out4)\n",
    "        # 将out5经过layer6得到out6\n",
    "        out6 = self.layer6(out5)\n",
    "        # 将out6经过dlayer6得到dout6\n",
    "        dout6 = self.dlayer6(out6)\n",
    "        # 将dout6和out5在通道维度上拼接得到dout6_out5\n",
    "        dout6_out5 = torch.cat([dout6, out5], 1)\n",
    "        # 将dout6_out5经过dlayer5得到dout5\n",
    "        dout5 = self.dlayer5(dout6_out5)\n",
    "        # 将dout5和out4在通道维度上拼接得到dout5_out4\n",
    "        dout5_out4 = torch.cat([dout5, out4], 1)\n",
    "        # 将dout5_out4经过dlayer4得到dout4\n",
    "        dout4 = self.dlayer4(dout5_out4)\n",
    "        # 将dout4和out3在通道维度上拼接得到dout4_out3\n",
    "        dout4_out3 = torch.cat([dout4, out3], 1)\n",
    "        # 将dout4_out3经过dlayer3得到dout3\n",
    "        dout3 = self.dlayer3(dout4_out3)\n",
    "        # 将dout3和out2b在通道维度上拼接得到dout3_out2b\n",
    "        dout3_out2b = torch.cat([dout3, out2b], 1)\n",
    "        # 将dout3_out2b经过dlayer2b得到dout2b\n",
    "        dout2b = self.dlayer2b(dout3_out2b)\n",
    "        # 将dout2b和out2在通道维度上拼接得到dout2b_out2\n",
    "        dout2b_out2 = torch.cat([dout2b, out2], 1)\n",
    "        # 将dout2b_out2经过dlayer2得到dout2\n",
    "        dout2 = self.dlayer2(dout2b_out2)\n",
    "        # 将dout2和out1在通道维度上拼接得到dout2_out1\n",
    "        dout2_out1 = torch.cat([dout2, out1], 1)\n",
    "        # 将dout2_out1经过dlayer1得到dout1\n",
    "        dout1 = self.dlayer1(dout2_out1)\n",
    "        # 返回dout1\n",
    "        return dout1,out6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('L')  # 转换为灰度图\n",
    "    airfoils_array = np.array(image)\n",
    "    airfoils_array = airfoils_array / 255.0  # 归一化\n",
    "    return airfoils_array\n",
    "\n",
    "# 加载并预处理图片\n",
    "image_folder_path = 'airfoils_img'  # 替换为你的图片文件夹路径\n",
    "# 获取image_folder_path路径下的所有文件，并存储在image_files列表中\n",
    "image_files = [f for f in os.listdir(image_folder_path) if os.path.isfile(os.path.join(image_folder_path, f))]\n",
    "input_images = [load_and_preprocess_image(os.path.join(image_folder_path, f)) for f in image_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集类\n",
    "class UnlabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_dir) \n",
    "                            if os.path.isfile(os.path.join(image_dir, f))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('L')  # 转换为灰度图\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # 确保图像是单通道灰度图\n",
    "    transforms.Resize((256, 256)),  # 调整图像大小到256*256\n",
    "    transforms.ToTensor(),  # 将图片转换为张量，并且将像素值归一化到 [0, 1] 范围\n",
    "])\n",
    "\n",
    "# 创建数据集\n",
    "dataset = UnlabeledImageDataset(image_dir='airfoils_img', transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 3. 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 4. 选择优化器\n",
    "model = TurbNetG()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 训练循环\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for images in dataloader:\n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        # 计算无监督损失\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        optimizer.step()       # 更新参数\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'airfoils_img\\waspsm.png'  # 图像的路径\n",
    "image = Image.open(image_path).convert('L')\n",
    "input_tensor = transform(image).unsqueeze(0)  # 添加批次维度\n",
    "with torch.no_grad():  # 不计算梯度\n",
    "    output,para = model(input_tensor)\n",
    "print(output[0].shape)\n",
    "print(type(output[0]))\n",
    "print(para[0].shape)\n",
    "# 将张量转换为 PIL.Image\n",
    "image = to_pil_image(output[0])\n",
    "\n",
    "# 显示图片\n",
    "image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
